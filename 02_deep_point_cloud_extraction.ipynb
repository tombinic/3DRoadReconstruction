{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23468,"status":"ok","timestamp":1718886646973,"user":{"displayName":"Andrea Bertogalli","userId":"10065050952247598131"},"user_tz":-120},"id":"GlyGVKAB8n7z","outputId":"eb46096a-6991-47ed-c0b9-1368efa98dfd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4877,"status":"ok","timestamp":1718886651843,"user":{"displayName":"Andrea Bertogalli","userId":"10065050952247598131"},"user_tz":-120},"id":"E0oIPOdfga-x","outputId":"74249f6d-5b6f-42b6-b4ea-f7e55bbc413c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'models'...\n","remote: Enumerating objects: 4107, done.\u001b[K\n","remote: Counting objects: 100% (4107/4107), done.\u001b[K\n","remote: Compressing objects: 100% (3108/3108), done.\u001b[K\n","remote: Total 4107 (delta 1188), reused 2033 (delta 937), pack-reused 0\u001b[K\n","Receiving objects: 100% (4107/4107), 45.35 MiB | 21.61 MiB/s, done.\n","Resolving deltas: 100% (1188/1188), done.\n"]}],"source":["import os\n","import pathlib\n","\n","# Clone the tensorflow models repository if it doesn't already exist\n","if \"models\" in pathlib.Path.cwd().parts:\n","  while \"models\" in pathlib.Path.cwd().parts:\n","    os.chdir('..')\n","elif not pathlib.Path('models').exists():\n","  !git clone --depth 1 https://github.com/tensorflow/models"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":132401,"status":"ok","timestamp":1718886784240,"user":{"displayName":"Andrea Bertogalli","userId":"10065050952247598131"},"user_tz":-120},"id":"0v21chvCgR7N","outputId":"4cddc0f3-aa55-41d1-d83f-5b9c6801625e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processing /content/models/research\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting avro-python3 (from object-detection==0.1)\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting apache-beam (from object-detection==0.1)\n","  Downloading apache_beam-2.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.5 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.5/14.5 MB 33.3 MB/s eta 0:00:00\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (9.4.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (4.9.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.7.1)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.0.10)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (21.6.0)\n","Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.16.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.0.7)\n","Collecting lvis (from object-detection==0.1)\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.11.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.0.3)\n","Collecting tf-models-official>=2.5.1 (from object-detection==0.1)\n","  Downloading tf_models_official-2.16.0-py2.py3-none-any.whl (2.7 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.7/2.7 MB 52.6 MB/s eta 0:00:00\n","Collecting tensorflow_io (from object-detection==0.1)\n","  Downloading tensorflow_io-0.37.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.6/49.6 MB 9.0 MB/s eta 0:00:00\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.15.0)\n","Collecting pyparsing==2.4.7 (from object-detection==0.1)\n","  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.8/67.8 kB 6.9 MB/s eta 0:00:00\n","Collecting sacrebleu<=2.2.0 (from object-detection==0.1)\n","  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.6/116.6 kB 13.4 MB/s eta 0:00:00\n","Collecting portalocker (from sacrebleu<=2.2.0->object-detection==0.1)\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2024.5.15)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.25.2)\n","Collecting colorama (from sacrebleu<=2.2.0->object-detection==0.1)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.84.0)\n","Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.2.0)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.6.14)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.10.0.82)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.5)\n","Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (9.0.0)\n","Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (6.0.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.99)\n","Collecting seqeval (from tf-models-official>=2.5.1->object-detection==0.1)\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 5.6 MB/s eta 0:00:00\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.9.6)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.16.1)\n","Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object-detection==0.1)\n","  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 242.5/242.5 kB 27.2 MB/s eta 0:00:00\n","Collecting tensorflow-text~=2.16.1 (from tf-models-official>=2.5.1->object-detection==0.1)\n","  Downloading tensorflow_text-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.2/5.2 MB 68.6 MB/s eta 0:00:00\n","Collecting tensorflow~=2.16.1 (from tf-models-official>=2.5.1->object-detection==0.1)\n","  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 589.8/589.8 MB 1.2 MB/s eta 0:00:00\n","Collecting tf-keras>=2.16.0 (from tf-models-official>=2.5.1->object-detection==0.1)\n","  Downloading tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 85.1 MB/s eta 0:00:00\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2024.1)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n","Collecting crcmod<2.0,>=1.7 (from apache-beam->object-detection==0.1)\n","  Downloading crcmod-1.7.tar.gz (89 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 89.7/89.7 kB 13.6 MB/s eta 0:00:00\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Collecting orjson<4,>=3.9.7 (from apache-beam->object-detection==0.1)\n","  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 145.0/145.0 kB 16.4 MB/s eta 0:00:00\n","Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object-detection==0.1)\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 152.0/152.0 kB 21.3 MB/s eta 0:00:00\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n","Collecting fastavro<2,>=0.23.6 (from apache-beam->object-detection==0.1)\n","  Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 70.4 MB/s eta 0:00:00\n","Collecting fasteners<1.0,>=0.3 (from apache-beam->object-detection==0.1)\n","  Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n","Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.64.1)\n","Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object-detection==0.1)\n","  Downloading hdfs-2.7.3.tar.gz (43 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.5/43.5 kB 6.1 MB/s eta 0:00:00\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.22.0)\n","Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (4.19.2)\n","Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (3.2.1)\n","Collecting objsize<0.8.0,>=0.6.1 (from apache-beam->object-detection==0.1)\n","  Downloading objsize-0.7.0-py3-none-any.whl (11 kB)\n","Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (24.1)\n","Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam->object-detection==0.1)\n","  Downloading pymongo-4.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (669 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 669.1/669.1 kB 44.9 MB/s eta 0:00:00\n","Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.23.0)\n","Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (3.20.3)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.4.2)\n","Collecting redis<6,>=5.0.0 (from apache-beam->object-detection==0.1)\n","  Downloading redis-5.0.6-py3-none-any.whl (252 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 252.0/252.0 kB 27.8 MB/s eta 0:00:00\n","Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.31.0)\n","Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (4.12.2)\n","Collecting zstandard<1,>=0.18.0 (from apache-beam->object-detection==0.1)\n","  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 89.8 MB/s eta 0:00:00\n","Requirement already satisfied: pyarrow<15.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.6)\n","Collecting js2py<1,>=0.74 (from apache-beam->object-detection==0.1)\n","  Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 68.5 MB/s eta 0:00:00\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (0.12.1)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (1.4.5)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (4.8.0.76)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (1.2.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (4.53.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io->object-detection==0.1) (0.37.0)\n","Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.27.0)\n","Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.1)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.1)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n","Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1)\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam->object-detection==0.1) (5.2)\n","Collecting pyjsparser>=2.5.1 (from js2py<1,>=0.74->apache-beam->object-detection==0.1)\n","  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (0.18.1)\n","Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2024.6.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.66.4)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.4)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.0.7)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.0)\n","Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->object-detection==0.1)\n","  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.7/307.7 kB 37.3 MB/s eta 0:00:00\n","Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam->object-detection==0.1) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.7)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Collecting h5py>=3.10.0 (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1)\n","  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.3/5.3 MB 103.3 MB/s eta 0:00:00\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (18.1.1)\n","Collecting ml-dtypes~=0.3.1 (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1)\n","  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 87.2 MB/s eta 0:00:00\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (67.7.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (2.4.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n","Collecting tensorboard<2.17,>=2.16 (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1)\n","  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.5/5.5 MB 82.6 MB/s eta 0:00:00\n","Collecting keras (from object-detection==0.1)\n","  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 70.5 MB/s eta 0:00:00\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->object-detection==0.1) (13.7.1)\n","Collecting namex (from keras->object-detection==0.1)\n","  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n","Collecting optree (from keras->object-detection==0.1)\n","  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 311.2/311.2 kB 38.4 MB/s eta 0:00:00\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.6.0)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->object-detection==0.1) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->object-detection==0.1) (2.16.1)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (8.1.7)\n","Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.1.5)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.15.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n","Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.5.1)\n","Requirement already satisfied: etils[enp,epath,epy,etree]>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.7.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (0.43.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2023.6.0)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (6.4.0)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.19.2)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.63.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.3)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->object-detection==0.1) (0.1.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.5.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (3.0.3)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (0.5.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Requirement already satisfied: docstring-parser~=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (2.1.5)\n","Building wheels for collected packages: object-detection, avro-python3, crcmod, dill, hdfs, seqeval, pyjsparser, docopt\n","  Building wheel for object-detection (setup.py): started\n","  Building wheel for object-detection (setup.py): finished with status 'done'\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1697356 sha256=c8d16345469ac07270360d3eeef455d928bbff60b724cbd3dbd36929a2852cbb\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-l7yidqhe/wheels/53/dd/70/2de274d6c443c69d367bd6a5606f95e5a6df61aacf1435ec0d\n","  Building wheel for avro-python3 (setup.py): started\n","  Building wheel for avro-python3 (setup.py): finished with status 'done'\n","  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43992 sha256=b6a127ee48f6f0571d3ef9b866b5beeeb7f7127d2b1b8baf8fd0ab3f53a6e1db\n","  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\n","  Building wheel for crcmod (setup.py): started\n","  Building wheel for crcmod (setup.py): finished with status 'done'\n","  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31408 sha256=897d6392f9e70aa0952cde40a06c3cb34f2a09df4d435376f9c2c1979b625f30\n","  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n","  Building wheel for dill (setup.py): started\n","  Building wheel for dill (setup.py): finished with status 'done'\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78541 sha256=8265e19cb954e7ac1c61479ef1f4b178a3b335dfbe7f5f558c20544dd868c9d9\n","  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n","  Building wheel for hdfs (setup.py): started\n","  Building wheel for hdfs (setup.py): finished with status 'done'\n","  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=748c963832ef5e98f8f4b1c2ba02780a87708ed7dd45f151605f478fb23fd181\n","  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n","  Building wheel for seqeval (setup.py): started\n","  Building wheel for seqeval (setup.py): finished with status 'done'\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=431e8f407dd18557c0b3774d262554bb70852d49f1753c7870105937f1a23809\n","  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n","  Building wheel for pyjsparser (setup.py): started\n","  Building wheel for pyjsparser (setup.py): finished with status 'done'\n","  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25984 sha256=e1df24bad5149096c3512063f649495859cecb18ce92242df851c54b0dcde818\n","  Stored in directory: /root/.cache/pip/wheels/5e/81/26/5956478df303e2bf5a85a5df595bb307bd25948a4bab69f7c7\n","  Building wheel for docopt (setup.py): started\n","  Building wheel for docopt (setup.py): finished with status 'done'\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=a291729b64b02f05e2412cd5079ae09c87a3754b3ad329a62096d2f124c365d2\n","  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n","Successfully built object-detection avro-python3 crcmod dill hdfs seqeval pyjsparser docopt\n","Installing collected packages: pyjsparser, namex, docopt, crcmod, zstandard, tensorflow-model-optimization, tensorflow_io, redis, pyparsing, portalocker, orjson, optree, objsize, ml-dtypes, js2py, h5py, fasteners, fastavro, dnspython, dill, colorama, avro-python3, tensorboard, sacrebleu, pymongo, hdfs, seqeval, lvis, keras, tensorflow, apache-beam, tf-keras, tensorflow-text, tf-models-official, object-detection\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 3.1.2\n","    Uninstalling pyparsing-3.1.2:\n","      Successfully uninstalled pyparsing-3.1.2\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml-dtypes 0.2.0\n","    Uninstalling ml-dtypes-0.2.0:\n","      Successfully uninstalled ml-dtypes-0.2.0\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.9.0\n","    Uninstalling h5py-3.9.0:\n","      Successfully uninstalled h5py-3.9.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.15.2\n","    Uninstalling tensorboard-2.15.2:\n","      Successfully uninstalled tensorboard-2.15.2\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.15.0\n","    Uninstalling keras-2.15.0:\n","      Successfully uninstalled keras-2.15.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.15.0\n","    Uninstalling tensorflow-2.15.0:\n","      Successfully uninstalled tensorflow-2.15.0\n","  Attempting uninstall: tf-keras\n","    Found existing installation: tf_keras 2.15.1\n","    Uninstalling tf_keras-2.15.1:\n","      Successfully uninstalled tf_keras-2.15.1\n","Successfully installed apache-beam-2.56.0 avro-python3-1.10.2 colorama-0.4.6 crcmod-1.7 dill-0.3.1.1 dnspython-2.6.1 docopt-0.6.2 fastavro-1.9.4 fasteners-0.19 h5py-3.11.0 hdfs-2.7.3 js2py-0.74 keras-3.3.3 lvis-0.5.3 ml-dtypes-0.3.2 namex-0.0.8 object-detection-0.1 objsize-0.7.0 optree-0.11.0 orjson-3.10.5 portalocker-2.8.2 pyjsparser-2.7.1 pymongo-4.7.3 pyparsing-2.4.7 redis-5.0.6 sacrebleu-2.2.0 seqeval-1.2.2 tensorboard-2.16.2 tensorflow-2.16.1 tensorflow-model-optimization-0.8.0 tensorflow-text-2.16.1 tensorflow_io-0.37.0 tf-keras-2.16.0 tf-models-official-2.16.0 zstandard-0.22.0\n"]}],"source":["# Install the Object Detection API\n","%%bash\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install ."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65416,"status":"ok","timestamp":1718886849649,"user":{"displayName":"Andrea Bertogalli","userId":"10065050952247598131"},"user_tz":-120},"id":"QJQdVjQagGKw","outputId":"86e80206-fafe-453a-a6af-ead38e9e7ac3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow==2.15.0\n","  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (18.1.1)\n","Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15.0)\n","  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.25.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (4.12.2)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.37.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.64.1)\n","Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.0)\n","  Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.0)\n","Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.0)\n","  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.43.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2024.6.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n","Installing collected packages: ml-dtypes, keras, tensorboard, tensorflow\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml-dtypes 0.3.2\n","    Uninstalling ml-dtypes-0.3.2:\n","      Successfully uninstalled ml-dtypes-0.3.2\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.3.3\n","    Uninstalling keras-3.3.3:\n","      Successfully uninstalled keras-3.3.3\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.16.2\n","    Uninstalling tensorboard-2.16.2:\n","      Successfully uninstalled tensorboard-2.16.2\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.16.1\n","    Uninstalling tensorflow-2.16.1:\n","      Successfully uninstalled tensorflow-2.16.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-text 2.16.1 requires tensorflow<2.17,>=2.16.1; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.15.0 which is incompatible.\n","tf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.15.0 which is incompatible.\n","tf-models-official 2.16.0 requires tensorflow~=2.16.1, but you have tensorflow 2.15.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.2.0 tensorboard-2.15.2 tensorflow-2.15.0\n"]}],"source":["!pip install tensorflow==\"2.15.0\""]},{"cell_type":"code","execution_count":6,"metadata":{"id":"8Tob-K6bgYMq","executionInfo":{"status":"ok","timestamp":1718886889879,"user_tz":-120,"elapsed":40234,"user":{"displayName":"Andrea Bertogalli","userId":"10065050952247598131"}}},"outputs":[],"source":["import tensorflow as tf\n","detection_model = tf.saved_model.load('/content/drive/MyDrive/IACV/Models/resnet_exported/saved_model')"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Cx0JnJSYucbk","executionInfo":{"status":"ok","timestamp":1718886891751,"user_tz":-120,"elapsed":1878,"user":{"displayName":"Andrea Bertogalli","userId":"10065050952247598131"}}},"outputs":[],"source":["from google.colab.patches import cv2_imshow\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from skimage import data, color, img_as_ubyte\n","from skimage.feature import canny\n","from skimage.transform import hough_ellipse\n","from skimage.draw import ellipse_perimeter\n","import math\n","\n","SCORE_TRESHOLD = 0.5\n","EXPANSION_FACTOR = 0.01\n","BINARY_IMAGE_TRESHOLD = 160\n","CANNY_LOW_TRESHOLD = 180\n","CANNY_HIGH_TRESHOLD = 200\n","WHEEL_TEMPLATE = cv2.imread(\"/content/drive/My Drive/IACV/wheel_template.png\")[:,:,0]\n","\n","def convert_bb_to_opencv(bb, frame):\n","  start = (int(bb[1] * frame.shape[1]), int(bb[0] * frame.shape[0]))\n","  end = (int(bb[3] * frame.shape[1]), int(bb[2] * frame.shape[0]))\n","  return start, end\n","\n","def convert_bbox_to_xywh(bbox, frame):\n","  bbox = convert_bb_to_opencv(bbox, frame)\n","  top_left = bbox[0]\n","  bottom_right = bbox[1]\n","\n","  x = top_left[0]\n","  y = top_left[1]\n","  width = bottom_right[0] - top_left[0]\n","  height = bottom_right[1] - top_left[1]\n","\n","  return (x, y, width, height)\n","\n","def add_bbox_to_frame(detection, frame):\n","  s, e = convert_bb_to_opencv(detection, frame)\n","  new_frame =  cv2.rectangle(frame, s, e, (0, 255, 0), 2)\n","  return new_frame\n","\n","def infer_boxes(frame, model):\n","    input_tensor = tf.convert_to_tensor([frame], dtype=tf.uint8)\n","    detections = model(input_tensor)\n","\n","    boxes = []\n","    for i, d in enumerate(detections['detection_scores'][0]):\n","      if d > SCORE_TRESHOLD:\n","        boxes.append(detections['detection_boxes'][0][i])\n","\n","    return boxes\n","\n","def add_boxes_to_frame(boxes, frame):\n","    for bbox in boxes:\n","      frame = add_bbox_to_frame(bbox, frame)\n","\n","    return frame\n","\n","def detect_wheels_ellipses(boxes, image):\n","  best_matches = []\n","  for box in boxes:\n","    x, y, w, h = convert_bbox_to_xywh(box, image)\n","    bbc_x, bbc_y = x+(w // 2), y+(h // 2)\n","    patch = image[y:y+h, x:x+w]\n","\n","    gray_image = cv2.cvtColor(patch, cv2.COLOR_BGR2GRAY)\n","    gray_image = cv2.equalizeHist(gray_image)\n","    _, binary_image = cv2.threshold(gray_image, BINARY_IMAGE_TRESHOLD, 255, cv2.THRESH_BINARY)\n","    binary_image = cv2.medianBlur(binary_image, ksize=5)\n","\n","    edges = cv2.Canny(binary_image, CANNY_LOW_TRESHOLD, CANNY_HIGH_TRESHOLD)\n","    contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n","\n","    #input_height, input_width = gray_image.shape[:2]\n","    #template = cv2.resize(WHEEL_TEMPLATE, (input_width, input_height), interpolation=cv2.INTER_AREA)\n","\n","    best_match_val = None\n","    best_match_ellipse = None\n","    for c in contours:\n","      if(len(c) < 5): continue\n","      ellipse = cv2.fitEllipse(c)\n","      (center, axes, angle) = ellipse\n","\n","      if not math.isnan(center[0]) and not math.isnan(center[1]):\n","        new_center = (int(center[0] + x), int(center[1] + y))\n","        new_ellipse = (new_center, axes, angle)\n","\n","        e_w, e_h = axes\n","        if(e_w < w / 2 or e_h < h / 2):\n","          continue\n","\n","        ellipse_points = cv2.ellipse2Poly(new_center, (int(e_w/2), int(e_h/2)), int(angle), 0, 360, 10)\n","\n","        if(not all(x <= point[0] <= x+w and y <= point[1] <= y+h for point in ellipse_points)):\n","          continue\n","\n","        ellipse_mask = np.zeros_like(gray_image)\n","        cv2.ellipse(ellipse_mask, ellipse, (255, 255, 255), -1)\n","        ellipse_roi = cv2.bitwise_and(binary_image, ellipse_mask)\n","\n","        '''\n","        result = cv2.matchTemplate(ellipse_roi, template, cv2.TM_CCOEFF_NORMED)\n","        _, max_val, _, max_loc = cv2.minMaxLoc(result)\n","\n","        if(best_match_val == None or max_val > best_match_val):\n","          best_match_dist = max_val\n","          best_match_ellipse = new_ellipse\n","        '''\n","\n","        dist = math.sqrt((bbc_x - new_center[0])**2 + (bbc_y - new_center[1])**2)\n","\n","        if(best_match_val == None or dist > best_match_val):\n","            best_match_dist = dist\n","            best_match_ellipse = new_ellipse\n","\n","    if(best_match_ellipse == None): continue\n","    best_matches.append(best_match_ellipse)\n","    image = cv2.ellipse(image, best_match_ellipse, (0, 255, 0), 2)\n","    image = cv2.circle(image, (bbc_x, bbc_y), 5, (255, 0, 255), -1)\n","  return image, best_matches\n","\n","def detect_contact_points(ellipses, frame):\n","  contact_points = []\n","  for ellipse in ellipses:\n","    (center, axes, angle) = ellipse\n","    e_w, e_h = axes\n","    ellipse_points = cv2.ellipse2Poly(center, (int(e_w/2), int(e_h/2)), int(angle), 0, 360, 10)\n","    contact_point = max(ellipse_points, key=lambda point: point[1])\n","    contact_points.append(contact_point)\n","    frame = cv2.circle(frame, (contact_point[0], contact_point[1]), 5, (0, 0, 255), -1)\n","\n","  return frame, contact_points"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280,"referenced_widgets":["6870e2e8ea8e446abafe6376a647d63d","d501169aa8354ec6a874483c8849b8c7","9cf504742b14427b88ae95c81c4ebc6d","795cb50b5f99431eb58d77baac6ed61a","3adb4757173f4f3f8e54210383b077b1","542f980c7cf44061880e2aaae8d7e3bf","db1932914689434ba243e3f41d070af6","3cce130154284a8bb817b53d6a3d0f1a","0aed6827ff904e1495b0f8a31fdc4c39","4513724dce7a4c34b0f443f306a14024","3d667b37cb56471b83c7111d746500fc","8c0aeb1826194b5090aa78a8dbbcab6e","b4ab9ffda21f46479819c2725b2cefe0","d0f868c0e3eb437dbf3185cca4d768a0","73aef80b27e244b7b37bb2da7845b750","e38f1fa378d446b58eef69d8573ff3f8","91f401f5d2a345b290e0253d19f02362","42b6f464e4c5451a8c7127de996ba00c","af949645afa54f63883e794277c6ca5b","b115fdd4bb1a46f6b6c6d7abddb48e58","b6b58e4b09d241a08231e062df66fa1a","4a21f13176004328ae0b55551b9f72a7","20edfa916e4342b189763e6c5bfc8ba1","39d3f0e535f0407db80d77a2657ce465","8e8cdfacadd84e03bae71f66e5268200","647cbcae535d43d2971e6215b22cfbb1","85717e8fd4174ecfa5a4cc7ccd05f129","072e4edf02ef475093c842409e4ea0c9","df31324ddaea4cdca5ea8c712baea591","fe58fef298f5460b83563d18890919b2","09e413dd58a64e60acd233c094f15d2b","6061a8e189094b10b54ed4c1a9ff380f","22be3291086843a181ee3d55cb910948"]},"executionInfo":{"elapsed":30177,"status":"ok","timestamp":1718886921924,"user":{"displayName":"Andrea Bertogalli","userId":"10065050952247598131"},"user_tz":-120},"id":"QSPj6Uk7yaLF","outputId":"fcb339be-33ac-4e97-a482-7b390663f1a7"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["preprocessor_config.json:   0%|          | 0.00/285 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6870e2e8ea8e446abafe6376a647d63d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/942 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c0aeb1826194b5090aa78a8dbbcab6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/1.37G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20edfa916e4342b189763e6c5bfc8ba1"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of DPTForDepthEstimation were not initialized from the model checkpoint at Intel/dpt-large and are newly initialized: ['neck.fusion_stage.layers.0.residual_layer1.convolution1.bias', 'neck.fusion_stage.layers.0.residual_layer1.convolution1.weight', 'neck.fusion_stage.layers.0.residual_layer1.convolution2.bias', 'neck.fusion_stage.layers.0.residual_layer1.convolution2.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoImageProcessor, DPTForDepthEstimation\n","import torch\n","from PIL import Image\n","\n","DX, DY = 100, 35\n","image_processor = AutoImageProcessor.from_pretrained(\"Intel/dpt-large\")\n","model = DPTForDepthEstimation.from_pretrained(\"Intel/dpt-large\")\n","\n","def generate_depth_map(frame):\n","  # prepare image for the model\n","  image = Image.fromarray(frame)\n","  inputs = image_processor(images=image, return_tensors=\"pt\")\n","\n","  with torch.no_grad():\n","      outputs = model(**inputs)\n","      predicted_depth = outputs.predicted_depth\n","\n","  # interpolate to original size\n","  prediction = torch.nn.functional.interpolate(\n","      predicted_depth.unsqueeze(1),\n","      size=image.size[::-1],\n","      mode=\"bicubic\",\n","      align_corners=False,\n","  )\n","\n","  output = prediction.squeeze().cpu().numpy()\n","  formatted = (output * 255 / np.max(output)).astype(\"uint8\")\n","  depth = Image.fromarray(formatted)\n","  return prediction[0][0], depth\n","\n","def compute_3D_coordinates(depth_map, pixels_coords):\n","  coords_3D = []\n","  for x, y in pixels_coords:\n","    z = depth_map[y][x].item()\n","    coords_3D.append((x, y, z))\n","\n","  return coords_3D\n","\n","def add_coords_label(frame, coordinates):\n","  text_color = (0, 0, 255)  # Red\n","  thickness = 2\n","  font_scale = 0.5\n","  font_face = cv2.FONT_HERSHEY_SIMPLEX\n","\n","  for x,y,z in coordinates:\n","    label_text = f'X: {round(x,2)}, Y: {round(y,2)}, Z: {round(z,2)}'\n","    frame = cv2.putText(frame, label_text, (x - DX, y + DY), font_face, font_scale, text_color, thickness)\n","  return frame"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"0ANcMFYM_azj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718888045007,"user_tz":-120,"elapsed":1123092,"user":{"displayName":"Andrea Bertogalli","userId":"10065050952247598131"}},"outputId":"6713abd9-fd57-4c79-8575-04abecdb9360"},"outputs":[{"output_type":"stream","name":"stderr","text":["Video processing progress:  59%|█████▉    | 165/280 [18:40<12:36,  6.57s/it]"]}],"source":["from tqdm import tqdm\n","import pandas as pd\n","import seaborn as sns\n","\n","video_path = '/content/drive/My Drive/IACV/Videos/video_curve_short.mp4'\n","cap = cv2.VideoCapture(video_path)\n","\n","num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","progress_bar = tqdm(total = num_frames, desc='Video processing progress', position=0, leave=True)\n","\n","frame_width = int(cap.get(3))\n","frame_height = int(cap.get(4))\n","\n","output_video_path = '/content/drive/My Drive/IACV/Processed_videos/F_RCNN_Deep_video_curve_short.mp4'\n","out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), 30, (frame_width, frame_height))\n","\n","pixels_coords = []\n","world_coords = []\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","      break\n","\n","    if frame is not None:\n","        boxes = infer_boxes(frame, detection_model)\n","        processed_frame = add_boxes_to_frame(boxes, frame)\n","        processed_frame, ellipses = detect_wheels_ellipses(boxes, processed_frame)\n","        processed_frame, contact_points = detect_contact_points(ellipses, processed_frame)\n","        pixels_coords += contact_points\n","        prediction, depth_map = generate_depth_map(frame)\n","        contact_points_3D = compute_3D_coordinates(prediction, contact_points)\n","\n","        world_coords += contact_points_3D\n","        processed_frame = add_coords_label(processed_frame, contact_points_3D)\n","\n","        #cv2_imshow(processed_frame)\n","        #sns.heatmap(depth_map)\n","        #plt.show()\n","\n","        out.write(frame)\n","        progress_bar.update(1)\n","\n","cap.release()\n","out.release()\n","\n","pd.DataFrame(world_coords).to_csv('/content/drive/My Drive/IACV/Point_coluds/F_RCNN_Deep_video_curve_short.csv', index=False)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6870e2e8ea8e446abafe6376a647d63d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d501169aa8354ec6a874483c8849b8c7","IPY_MODEL_9cf504742b14427b88ae95c81c4ebc6d","IPY_MODEL_795cb50b5f99431eb58d77baac6ed61a"],"layout":"IPY_MODEL_3adb4757173f4f3f8e54210383b077b1"}},"d501169aa8354ec6a874483c8849b8c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_542f980c7cf44061880e2aaae8d7e3bf","placeholder":"​","style":"IPY_MODEL_db1932914689434ba243e3f41d070af6","value":"preprocessor_config.json: 100%"}},"9cf504742b14427b88ae95c81c4ebc6d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3cce130154284a8bb817b53d6a3d0f1a","max":285,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0aed6827ff904e1495b0f8a31fdc4c39","value":285}},"795cb50b5f99431eb58d77baac6ed61a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4513724dce7a4c34b0f443f306a14024","placeholder":"​","style":"IPY_MODEL_3d667b37cb56471b83c7111d746500fc","value":" 285/285 [00:00&lt;00:00, 5.53kB/s]"}},"3adb4757173f4f3f8e54210383b077b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"542f980c7cf44061880e2aaae8d7e3bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db1932914689434ba243e3f41d070af6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3cce130154284a8bb817b53d6a3d0f1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0aed6827ff904e1495b0f8a31fdc4c39":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4513724dce7a4c34b0f443f306a14024":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d667b37cb56471b83c7111d746500fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c0aeb1826194b5090aa78a8dbbcab6e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b4ab9ffda21f46479819c2725b2cefe0","IPY_MODEL_d0f868c0e3eb437dbf3185cca4d768a0","IPY_MODEL_73aef80b27e244b7b37bb2da7845b750"],"layout":"IPY_MODEL_e38f1fa378d446b58eef69d8573ff3f8"}},"b4ab9ffda21f46479819c2725b2cefe0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91f401f5d2a345b290e0253d19f02362","placeholder":"​","style":"IPY_MODEL_42b6f464e4c5451a8c7127de996ba00c","value":"config.json: 100%"}},"d0f868c0e3eb437dbf3185cca4d768a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af949645afa54f63883e794277c6ca5b","max":942,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b115fdd4bb1a46f6b6c6d7abddb48e58","value":942}},"73aef80b27e244b7b37bb2da7845b750":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6b58e4b09d241a08231e062df66fa1a","placeholder":"​","style":"IPY_MODEL_4a21f13176004328ae0b55551b9f72a7","value":" 942/942 [00:00&lt;00:00, 26.3kB/s]"}},"e38f1fa378d446b58eef69d8573ff3f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91f401f5d2a345b290e0253d19f02362":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42b6f464e4c5451a8c7127de996ba00c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af949645afa54f63883e794277c6ca5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b115fdd4bb1a46f6b6c6d7abddb48e58":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b6b58e4b09d241a08231e062df66fa1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a21f13176004328ae0b55551b9f72a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20edfa916e4342b189763e6c5bfc8ba1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_39d3f0e535f0407db80d77a2657ce465","IPY_MODEL_8e8cdfacadd84e03bae71f66e5268200","IPY_MODEL_647cbcae535d43d2971e6215b22cfbb1"],"layout":"IPY_MODEL_85717e8fd4174ecfa5a4cc7ccd05f129"}},"39d3f0e535f0407db80d77a2657ce465":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_072e4edf02ef475093c842409e4ea0c9","placeholder":"​","style":"IPY_MODEL_df31324ddaea4cdca5ea8c712baea591","value":"model.safetensors: 100%"}},"8e8cdfacadd84e03bae71f66e5268200":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe58fef298f5460b83563d18890919b2","max":1367456044,"min":0,"orientation":"horizontal","style":"IPY_MODEL_09e413dd58a64e60acd233c094f15d2b","value":1367456044}},"647cbcae535d43d2971e6215b22cfbb1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6061a8e189094b10b54ed4c1a9ff380f","placeholder":"​","style":"IPY_MODEL_22be3291086843a181ee3d55cb910948","value":" 1.37G/1.37G [00:12&lt;00:00, 117MB/s]"}},"85717e8fd4174ecfa5a4cc7ccd05f129":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"072e4edf02ef475093c842409e4ea0c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df31324ddaea4cdca5ea8c712baea591":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe58fef298f5460b83563d18890919b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09e413dd58a64e60acd233c094f15d2b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6061a8e189094b10b54ed4c1a9ff380f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22be3291086843a181ee3d55cb910948":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}